#!/usr/bin/env python3
"""
å¢é‡è™•ç†æ¨¡å¡Š
è² è²¬è¿½è¹¤å’Œè™•ç†é …ç›®ä¸­çš„å¢é‡è®ŠåŒ–
æ”¯æŒæ–·é»çºŒå‚³å’Œç‹€æ…‹ç®¡ç†
"""

import os
import json
import hashlib
import pickle
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime
import shutil


class IncrementalProcessingModule:
    """å¢é‡è™•ç†æ¨¡å¡Š"""
    
    def __init__(self, project_path: str, state_dir: str = ".incremental_state"):
        """
        åˆå§‹åŒ–å¢é‡è™•ç†æ¨¡å¡Š
        
        Args:
            project_path: é …ç›®è·¯å¾‘
            state_dir: ç‹€æ…‹æ–‡ä»¶å­˜å„²ç›®éŒ„
        """
        self.project_path = Path(project_path)
        self.state_dir = self.project_path / state_dir
        self.state_dir.mkdir(parents=True, exist_ok=True)
        
        # ç‹€æ…‹æ–‡ä»¶è·¯å¾‘
        self.state_file = self.state_dir / "processing_state.pkl"
        self.file_hashes_file = self.state_dir / "file_hashes.json"
        self.processing_history_file = self.state_dir / "processing_history.json"
        
        # åŠ è¼‰ç‹€æ…‹
        self.state = self._load_state()
        self.file_hashes = self._load_file_hashes()
        self.processing_history = self._load_processing_history()
        
        # çµ±è¨ˆä¿¡æ¯
        self.stats = {
            "total_files_processed": 0,
            "new_files_processed": 0,
            "modified_files_processed": 0,
            "unchanged_files_skipped": 0,
            "processing_time_saved": 0.0
        }
    
    def _load_state(self) -> Dict[str, Any]:
        """åŠ è¼‰è™•ç†ç‹€æ…‹"""
        if self.state_file.exists():
            try:
                with open(self.state_file, 'rb') as f:
                    return pickle.load(f)
            except Exception as e:
                print(f"âš ï¸  ç„¡æ³•åŠ è¼‰ç‹€æ…‹æ–‡ä»¶: {e}")
        
        # é»˜èªç‹€æ…‹
        return {
            "last_processed_time": None,
            "current_phase": None,
            "completed_phases": [],
            "pending_files": [],
            "processed_files": [],
            "errors": []
        }
    
    def _save_state(self):
        """ä¿å­˜è™•ç†ç‹€æ…‹"""
        try:
            with open(self.state_file, 'wb') as f:
                pickle.dump(self.state, f)
        except Exception as e:
            print(f"âš ï¸  ç„¡æ³•ä¿å­˜ç‹€æ…‹æ–‡ä»¶: {e}")
    
    def _load_file_hashes(self) -> Dict[str, str]:
        """åŠ è¼‰æ–‡ä»¶å“ˆå¸Œå€¼"""
        if self.file_hashes_file.exists():
            try:
                with open(self.file_hashes_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸  ç„¡æ³•åŠ è¼‰æ–‡ä»¶å“ˆå¸Œ: {e}")
        
        return {}
    
    def _save_file_hashes(self):
        """ä¿å­˜æ–‡ä»¶å“ˆå¸Œå€¼"""
        try:
            with open(self.file_hashes_file, 'w', encoding='utf-8') as f:
                json.dump(self.file_hashes, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âš ï¸  ç„¡æ³•ä¿å­˜æ–‡ä»¶å“ˆå¸Œ: {e}")
    
    def _load_processing_history(self) -> List[Dict[str, Any]]:
        """åŠ è¼‰è™•ç†æ­·å²"""
        if self.processing_history_file.exists():
            try:
                with open(self.processing_history_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"âš ï¸  ç„¡æ³•åŠ è¼‰è™•ç†æ­·å²: {e}")
        
        return []
    
    def _save_processing_history(self):
        """ä¿å­˜è™•ç†æ­·å²"""
        try:
            with open(self.processing_history_file, 'w', encoding='utf-8') as f:
                json.dump(self.processing_history, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âš ï¸  ç„¡æ³•ä¿å­˜è™•ç†æ­·å²: {e}")
    
    def _calculate_file_hash(self, file_path: Path) -> str:
        """è¨ˆç®—æ–‡ä»¶å“ˆå¸Œå€¼"""
        try:
            with open(file_path, 'rb') as f:
                file_content = f.read()
                return hashlib.md5(file_content).hexdigest()
        except Exception as e:
            print(f"âš ï¸  ç„¡æ³•è¨ˆç®—æ–‡ä»¶å“ˆå¸Œ {file_path}: {e}")
            return ""
    
    def _get_all_project_files(self, extensions: Optional[List[str]] = None) -> List[Path]:
        """ç²å–é …ç›®ä¸­æ‰€æœ‰æ–‡ä»¶"""
        files = []
        
        for root, dirs, filenames in os.walk(self.project_path):
            # è·³éç‹€æ…‹ç›®éŒ„
            if self.state_dir in Path(root).parents:
                continue
            
            for filename in filenames:
                file_path = Path(root) / filename
                
                # éæ¿¾æ“´å±•å
                if extensions:
                    if file_path.suffix.lower() not in extensions:
                        continue
                
                files.append(file_path)
        
        return files
    def detect_changes(self, extensions: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        æª¢æ¸¬é …ç›®ä¸­çš„è®ŠåŒ–
        
        Args:
            extensions: è¦ç›£æ§çš„æ–‡ä»¶æ“´å±•ååˆ—è¡¨
            
        Returns:
            è®ŠåŒ–æª¢æ¸¬çµæœ
        """
        print("ğŸ” æª¢æ¸¬é …ç›®è®ŠåŒ–...")
        
        current_files = self._get_all_project_files(extensions)
        changes = {
            "new_files": [],
            "modified_files": [],
            "deleted_files": [],
            "unchanged_files": []
        }
        
        # è¨ˆç®—ç•¶å‰æ–‡ä»¶å“ˆå¸Œ
        current_hashes = {}
        for file_path in current_files:
            rel_path = str(file_path.relative_to(self.project_path))
            file_hash = self._calculate_file_hash(file_path)
            if file_hash:
                current_hashes[rel_path] = file_hash
        
        # æª¢æ¸¬æ–°æ–‡ä»¶å’Œä¿®æ”¹çš„æ–‡ä»¶
        for rel_path, current_hash in current_hashes.items():
            old_hash = self.file_hashes.get(rel_path)
            
            if old_hash is None:
                changes["new_files"].append(rel_path)
            elif old_hash != current_hash:
                changes["modified_files"].append(rel_path)
            else:
                changes["unchanged_files"].append(rel_path)
        
        # æª¢æ¸¬åˆªé™¤çš„æ–‡ä»¶
        for rel_path in self.file_hashes.keys():
            if rel_path not in current_hashes:
                changes["deleted_files"].append(rel_path)
        
        # æ›´æ–°çµ±è¨ˆ
        self.stats["total_files_processed"] = len(current_files)
        
        print(f"âœ… è®ŠåŒ–æª¢æ¸¬å®Œæˆ:")
        print(f"   æ–°æ–‡ä»¶: {len(changes['new_files'])} å€‹")
        print(f"   ä¿®æ”¹çš„æ–‡ä»¶: {len(changes['modified_files'])} å€‹")
        print(f"   åˆªé™¤çš„æ–‡ä»¶: {len(changes['deleted_files'])} å€‹")
        print(f"   æœªè®ŠåŒ–çš„æ–‡ä»¶: {len(changes['unchanged_files'])} å€‹")
        
        return changes
    
    def process_incrementally(self, 
                             processor_func, 
                             extensions: Optional[List[str]] = None,
                             batch_size: int = 10) -> Dict[str, Any]:
        """
        å¢é‡è™•ç†é …ç›®
        
        Args:
            processor_func: è™•ç†å‡½æ•¸ï¼Œæ¥å—æ–‡ä»¶è·¯å¾‘åƒæ•¸
            extensions: è¦è™•ç†çš„æ–‡ä»¶æ“´å±•ååˆ—è¡¨
            batch_size: æ¯æ‰¹è™•ç†çš„æ–‡ä»¶æ•¸é‡
            
        Returns:
            è™•ç†çµæœ
        """
        print("ğŸ”„ é–‹å§‹å¢é‡è™•ç†...")
        
        # æª¢æ¸¬è®ŠåŒ–
        changes = self.detect_changes(extensions)
        
        # æº–å‚™è¦è™•ç†çš„æ–‡ä»¶
        files_to_process = changes["new_files"] + changes["modified_files"]
        
        if not files_to_process:
            print("âœ… æ²’æœ‰éœ€è¦è™•ç†çš„æ–‡ä»¶ï¼Œè·³éè™•ç†")
            return {
                "status": "skipped",
                "reason": "no_changes",
                "changes": changes
            }
        
        print(f"ğŸ“‹ éœ€è¦è™•ç† {len(files_to_process)} å€‹æ–‡ä»¶")
        
        # åˆ†æ‰¹è™•ç†
        results = {
            "processed_files": [],
            "successful": 0,
            "failed": 0,
            "errors": [],
            "batch_results": []
        }
        
        for i in range(0, len(files_to_process), batch_size):
            batch = files_to_process[i:i + batch_size]
            batch_num = i // batch_size + 1
            total_batches = (len(files_to_process) + batch_size - 1) // batch_size
            
            print(f"\nğŸ“¦ è™•ç†æ‰¹æ¬¡ {batch_num}/{total_batches} ({len(batch)} å€‹æ–‡ä»¶)")
            
            batch_result = {
                "batch_number": batch_num,
                "files": [],
                "successful": 0,
                "failed": 0
            }
            
            for rel_path in batch:
                file_path = self.project_path / rel_path
                
                try:
                    print(f"  ğŸ“„ è™•ç†: {rel_path}")
                    
                    # èª¿ç”¨è™•ç†å‡½æ•¸
                    file_result = processor_func(str(file_path))
                    
                    # æ›´æ–°æ–‡ä»¶å“ˆå¸Œ
                    self.file_hashes[rel_path] = self._calculate_file_hash(file_path)
                    
                    batch_result["files"].append({
                        "path": rel_path,
                        "status": "success",
                        "result": file_result
                    })
                    batch_result["successful"] += 1
                    
                    # æ›´æ–°çµ±è¨ˆ
                    if rel_path in changes["new_files"]:
                        self.stats["new_files_processed"] += 1
                    else:
                        self.stats["modified_files_processed"] += 1
                    
                except Exception as e:
                    print(f"  âŒ è™•ç†å¤±æ•— {rel_path}: {e}")
                    
                    batch_result["files"].append({
                        "path": rel_path,
                        "status": "failed",
                        "error": str(e)
                    })
                    batch_result["failed"] += 1
                    
                    results["errors"].append({
                        "file": rel_path,
                        "error": str(e)
                    })
            
            results["batch_results"].append(batch_result)
            results["successful"] += batch_result["successful"]
            results["failed"] += batch_result["failed"]
            
            # ä¿å­˜ç‹€æ…‹ï¼ˆæ–·é»çºŒå‚³ï¼‰
            self._save_state()
            self._save_file_hashes()
        
        # æ›´æ–°è™•ç†æ­·å²
        history_entry = {
            "timestamp": datetime.now().isoformat(),
            "changes_detected": {
                "new_files": len(changes["new_files"]),
                "modified_files": len(changes["modified_files"]),
                "deleted_files": len(changes["deleted_files"])
            },
            "processing_results": {
                "total_processed": len(files_to_process),
                "successful": results["successful"],
                "failed": results["failed"]
            },
            "stats": self.stats.copy()
        }
        
        self.processing_history.append(history_entry)
        
        # ä¿å­˜æ‰€æœ‰ç‹€æ…‹
        self._save_state()
        self._save_file_hashes()
        self._save_processing_history()
        
        # æ›´æ–°æœ€å¾Œè™•ç†æ™‚é–“
        self.state["last_processed_time"] = datetime.now().isoformat()
        
        print(f"\nâœ… å¢é‡è™•ç†å®Œæˆ:")
        print(f"   æˆåŠŸè™•ç†: {results['successful']} å€‹æ–‡ä»¶")
        print(f"   è™•ç†å¤±æ•—: {results['failed']} å€‹æ–‡ä»¶")
        print(f"   è·³éè™•ç†: {len(changes['unchanged_files'])} å€‹æœªè®ŠåŒ–æ–‡ä»¶")
        
        return {
            "status": "completed",
            "results": results,
            "changes": changes,
            "stats": self.stats
        }
    def resume_processing(self, processor_func, batch_size: int = 10) -> Dict[str, Any]:
        """
        æ¢å¾©ä¸­æ–·çš„è™•ç†
        
        Args:
            processor_func: è™•ç†å‡½æ•¸
            batch_size: æ¯æ‰¹è™•ç†çš„æ–‡ä»¶æ•¸é‡
            
        Returns:
            æ¢å¾©è™•ç†çµæœ
        """
        print("ğŸ”„ æ¢å¾©ä¸­æ–·çš„è™•ç†...")
        
        if not self.state.get("pending_files"):
            print("âœ… æ²’æœ‰å¾…è™•ç†çš„æ–‡ä»¶")
            return {
                "status": "no_pending_files",
                "message": "æ²’æœ‰å¾…è™•ç†çš„æ–‡ä»¶"
            }
        
        pending_files = self.state["pending_files"]
        print(f"ğŸ“‹ æ¢å¾© {len(pending_files)} å€‹å¾…è™•ç†æ–‡ä»¶")
        
        results = self.process_incrementally(
            processor_func=processor_func,
            batch_size=batch_size
        )
        
        # æ¸…ç©ºå¾…è™•ç†æ–‡ä»¶åˆ—è¡¨
        self.state["pending_files"] = []
        self._save_state()
        
        return results
    
    def get_processing_summary(self) -> Dict[str, Any]:
        """ç²å–è™•ç†æ‘˜è¦"""
        return {
            "project_info": {
                "path": str(self.project_path),
                "state_directory": str(self.state_dir)
            },
            "current_state": self.state,
            "file_tracking": {
                "tracked_files": len(self.file_hashes),
                "last_updated": self.state.get("last_processed_time")
            },
            "processing_history": {
                "total_runs": len(self.processing_history),
                "last_run": self.processing_history[-1] if self.processing_history else None
            },
            "statistics": self.stats
        }
    
    def clear_state(self, confirm: bool = False) -> bool:
        """
        æ¸…é™¤è™•ç†ç‹€æ…‹
        
        Args:
            confirm: ç¢ºèªæ¸…é™¤
            
        Returns:
            æ˜¯å¦æˆåŠŸæ¸…é™¤
        """
        if not confirm:
            print("âš ï¸  è«‹è¨­ç½® confirm=True ä¾†ç¢ºèªæ¸…é™¤ç‹€æ…‹")
            return False
        
        try:
            # åˆªé™¤ç‹€æ…‹ç›®éŒ„
            if self.state_dir.exists():
                shutil.rmtree(self.state_dir)
                print(f"âœ… å·²æ¸…é™¤ç‹€æ…‹ç›®éŒ„: {self.state_dir}")
            
            # é‡ç½®ç‹€æ…‹
            self.state_dir.mkdir(parents=True, exist_ok=True)
            self.state = self._load_state()
            self.file_hashes = self._load_file_hashes()
            self.processing_history = self._load_processing_history()
            self.stats = {
                "total_files_processed": 0,
                "new_files_processed": 0,
                "modified_files_processed": 0,
                "unchanged_files_skipped": 0,
                "processing_time_saved": 0.0
            }
            
            return True
            
        except Exception as e:
            print(f"âŒ æ¸…é™¤ç‹€æ…‹å¤±æ•—: {e}")
            return False
    
    def estimate_time_savings(self, avg_processing_time_per_file: float = 0.5) -> Dict[str, Any]:
        """
        ä¼°è¨ˆå¢é‡è™•ç†ç¯€çœçš„æ™‚é–“
        
        Args:
            avg_processing_time_per_file: å¹³å‡æ¯å€‹æ–‡ä»¶çš„è™•ç†æ™‚é–“ï¼ˆç§’ï¼‰
            
        Returns:
            æ™‚é–“ç¯€çœä¼°è¨ˆ
        """
        unchanged_files = self.stats["unchanged_files_skipped"]
        time_saved = unchanged_files * avg_processing_time_per_file
        
        self.stats["processing_time_saved"] = time_saved
        
        return {
            "unchanged_files_skipped": unchanged_files,
            "avg_processing_time_per_file": avg_processing_time_per_file,
            "estimated_time_saved_seconds": time_saved,
            "estimated_time_saved_minutes": time_saved / 60,
            "estimated_time_saved_hours": time_saved / 3600
        }

# ç¤ºä¾‹è™•ç†å‡½æ•¸
def example_file_processor(file_path: str) -> Dict[str, Any]:
    """
    ç¤ºä¾‹æ–‡ä»¶è™•ç†å‡½æ•¸
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾‘
        
    Returns:
        è™•ç†çµæœ
    """
    path = Path(file_path)
    
    # é€™è£¡å¯ä»¥å¯¦ç¾å…·é«”çš„è™•ç†é‚è¼¯
    # ä¾‹å¦‚ï¼šä»£ç¢¼åˆ†æã€æ–‡æª”ç”Ÿæˆã€è³ªé‡æª¢æŸ¥ç­‰
    
    result = {
        "file_path": str(path),
        "file_size": path.stat().st_size if path.exists() else 0,
        "file_type": path.suffix,
        "processed_at": datetime.now().isoformat(),
        "analysis_result": {
            "lines_of_code": 0,
            "complexity_score": 0,
            "issues_found": []
        }
    }
    
    return result


def main():
    """ä¸»å‡½æ•¸ - æ¸¬è©¦å¢é‡è™•ç†æ¨¡å¡Š"""
    import sys
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python incremental_processing_module.py <é …ç›®è·¯å¾‘>")
        print("ç¤ºä¾‹: python incremental_processing_module.py /path/to/your/project")
        sys.exit(1)
    
    project_path = sys.argv[1]
    
    if not os.path.exists(project_path):
        print(f"éŒ¯èª¤: é …ç›®è·¯å¾‘ä¸å­˜åœ¨: {project_path}")
        sys.exit(1)
    
    print("=" * 70)
    print("ğŸš€ å¢é‡è™•ç†æ¨¡å¡Šæ¸¬è©¦")
    print("=" * 70)
    
    # å‰µå»ºå¢é‡è™•ç†æ¨¡å¡Š
    incremental_module = IncrementalProcessingModule(project_path)
    
    # ç²å–è™•ç†æ‘˜è¦
    print("\nğŸ“Š ç•¶å‰è™•ç†æ‘˜è¦:")
    summary = incremental_module.get_processing_summary()
    print(f"   é …ç›®è·¯å¾‘: {summary['project_info']['path']}")
    print(f"   è¿½è¹¤æ–‡ä»¶æ•¸: {summary['file_tracking']['tracked_files']}")
    print(f"   è™•ç†æ­·å²æ¬¡æ•¸: {summary['processing_history']['total_runs']}")
    
    # æª¢æ¸¬è®ŠåŒ–
    print("\nğŸ” æª¢æ¸¬é …ç›®è®ŠåŒ–:")
    changes = incremental_module.detect_changes([".py", ".js", ".ts", ".java", ".go"])
    
    # åŸ·è¡Œå¢é‡è™•ç†
    print("\nğŸ”„ åŸ·è¡Œå¢é‡è™•ç†:")
    results = incremental_module.process_incrementally(
        processor_func=example_file_processor,
        extensions=[".py", ".js", ".ts"],
        batch_size=5
    )
    
    # é¡¯ç¤ºçµæœ
    print("\nğŸ“ˆ è™•ç†çµæœ:")
    print(f"   ç‹€æ…‹: {results['status']}")
    print(f"   æˆåŠŸè™•ç†: {results['results']['successful']} å€‹æ–‡ä»¶")
    print(f"   è™•ç†å¤±æ•—: {results['results']['failed']} å€‹æ–‡ä»¶")
    
    # ä¼°è¨ˆæ™‚é–“ç¯€çœ
    print("\nâ±ï¸  æ™‚é–“ç¯€çœä¼°è¨ˆ:")
    time_savings = incremental_module.estimate_time_savings()
    print(f"   è·³éæœªè®ŠåŒ–æ–‡ä»¶: {time_savings['unchanged_files_skipped']} å€‹")
    print(f"   ä¼°è¨ˆç¯€çœæ™‚é–“: {time_savings['estimated_time_saved_minutes']:.2f} åˆ†é˜")
    
    print("\n" + "=" * 70)
    print("âœ… å¢é‡è™•ç†æ¨¡å¡Šæ¸¬è©¦å®Œæˆ")
    print("=" * 70)


if __name__ == "__main__":
    main()
